{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac7a768410260ab7",
   "metadata": {},
   "source": [
    "Setup PyTorch to use best hardware option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e771aa12042c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T21:53:09.211467Z",
     "start_time": "2024-09-27T21:53:09.208342Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e6fe5b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACTS_BASE = '../../../artifacts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "16a661dc4242d3d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T21:53:17.696501Z",
     "start_time": "2024-09-27T21:53:10.408499Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import path\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dataset_path = path.join(ARTIFACTS_BASE, 'datasets', 'jayavibhav/prompt-injection')\n",
    "\n",
    "train_dataset_split = load_from_disk(path.join(dataset_path, 'train')).train_test_split(test_size=0.2)\n",
    "train_dataset = train_dataset_split['train'].rename_column('text', 'prompt').select(range(1000))\n",
    "eval_dataset = train_dataset_split['test'].rename_column('text', 'prompt').select(range(1000))\n",
    "\n",
    "train_dataset = train_dataset.rename_column('label', 'labels')\n",
    "eval_dataset = eval_dataset.rename_column('label', 'labels')\n",
    "\n",
    "test_dataset = load_from_disk(path.join(dataset_path, 'test'))\n",
    "test_dataset = test_dataset.rename_column('text', 'prompt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab03e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a52b923",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d54d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3bdbda6052d893",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:05:33.083468Z",
     "start_time": "2024-09-27T22:05:29.881537Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert/distilroberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, clean_up_tokenization_spaces=False, use_fast=True, max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4db58cbf5792a148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:05:59.112142Z",
     "start_time": "2024-09-27T22:05:59.107897Z"
    }
   },
   "outputs": [],
   "source": [
    "# A utility function to receive a batch of data and tokenize the prompts\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(batch['prompt'], padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fb7289290d6de7c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:07:08.775999Z",
     "start_time": "2024-09-27T22:06:18.067141Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize prompts in both training and testing datasets\n",
    "prompts_train_tokenized = train_dataset.map(tokenize_batch, batched=True) \n",
    "prompts_eval_tokenized = eval_dataset.map(tokenize_batch, batched=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c536804a732aed9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:07:47.205010Z",
     "start_time": "2024-09-27T22:07:47.199315Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import TrainingArguments to handle the various training configurations\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Define training arguments for fine-tuning\n",
    "# GPU NVIDIA RTX A6000\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./results/logs\",\n",
    "    save_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    tf32=True,\n",
    "    num_train_epochs=3,\n",
    "    torch_compile=True,\n",
    "    load_best_model_at_end=True,\n",
    "    dataloader_num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f36b1522a52c541a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:08:06.839222Z",
     "start_time": "2024-09-27T22:08:06.830500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize a DataFrame to track the model's performance\n",
    "results_df = pd.DataFrame(columns=[\"epoch\",\"accuracy\",\"precision\",\"recall\",\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bd817fbd7f16e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:08:26.753974Z",
     "start_time": "2024-09-27T22:08:26.749437Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import accuracy metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# A utility function for model evaluation during fine-tuning\n",
    "def evaluate_model(trainer, epoch):\n",
    "    \n",
    "    # Extract predictions and labels\n",
    "    predictions = trainer.predictions.argmax(axis=1)\n",
    "\n",
    "    labels = trainer.label_ids\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    # Calculate precision, recall, and f1 score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
    "    \n",
    "    # Append current metrics to results\n",
    "    global results_df\n",
    "    results_df.loc[len(results_df)] = [epoch, accuracy, precision, recall, f1]\n",
    "        \n",
    "    # Return\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "edccddca7a3676d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:08:45.793722Z",
     "start_time": "2024-09-27T22:08:45.757700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the Trainer class\n",
    "from transformers import Trainer\n",
    "\n",
    "# Define trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=prompts_train_tokenized,\n",
    "    eval_dataset=prompts_eval_tokenized,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=lambda p: evaluate_model(p, trainer.state.epoch),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ffd5c792823ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:09:18.107894Z",
     "start_time": "2024-09-27T22:09:06.172408Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251eeadc807ff2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be87eec9-a0fa-4c45-9128-06431286016f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the accuracy in each epoch\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "# Plot samples\n",
    "sns.lineplot(data=results_df, x=\"epoch\", y=\"accuracy\")\n",
    "\n",
    "# Set figure title and axes labels\n",
    "plt.title(\"Model accuracy in each epoch\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f64cc4-7371-485c-830f-79e0df855b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = trainer.evaluate()\n",
    "print(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd7525-cd46-4379-b1c7-43237d883c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./final_results\"\n",
    "model.save_pretrained(output_dir + \"/distilbert-base-uncased-finetuned-sst-2-english-model\")\n",
    "tokenizer.save_pretrained(output_dir + \"/distilbert-base-uncased-finetuned-sst-2-english-tokenizer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
