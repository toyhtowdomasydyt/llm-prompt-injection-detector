{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac7a768410260ab7",
   "metadata": {},
   "source": [
    "Setup PyTorch to use best hardware option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13e771aa12042c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T21:53:09.211467Z",
     "start_time": "2024-09-27T21:53:09.208342Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16a661dc4242d3d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T21:53:17.696501Z",
     "start_time": "2024-09-27T21:53:10.408499Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "splits = {'train': 'data/train-00000-of-00001.parquet', 'test': 'data/test-00000-of-00001.parquet'}\n",
    "train_df = pd.read_parquet(\"hf://datasets/jayavibhav/prompt-injection/\" + splits[\"train\"])\n",
    "test_df = pd.read_parquet(\"hf://datasets/jayavibhav/prompt-injection/\" + splits[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9431009f0e075416",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T21:53:19.027239Z",
     "start_time": "2024-09-27T21:53:19.024216Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df.rename(columns={\"text\":\"prompt\"}, inplace=True)\n",
    "train_df.rename(columns={\"text\":\"prompt\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3bdbda6052d893",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:05:33.083468Z",
     "start_time": "2024-09-27T22:05:29.881537Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"microsoft/deberta-v3-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, clean_up_tokenization_spaces=False, use_fast=True, max_length=512)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4db58cbf5792a148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:05:59.112142Z",
     "start_time": "2024-09-27T22:05:59.107897Z"
    }
   },
   "outputs": [],
   "source": [
    "# A utility function to receive a batch of data and tokenize the prompts\n",
    "def tokenize_batch(batch):\n",
    "    return tokenizer(batch['prompt'], padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb7289290d6de7c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:07:08.775999Z",
     "start_time": "2024-09-27T22:06:18.067141Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize prompts in both training and testing datasets\n",
    "prompts_train_tokenized = tokenize_batch(train_df.to_dict(orient='list'))\n",
    "prompts_test_tokenized = tokenize_batch(test_df.to_dict(orient='list'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b3c0ee9cd6a159b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:07:28.259319Z",
     "start_time": "2024-09-27T22:07:28.255474Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import Dataloader\n",
    "\n",
    "train_dataset = DataLoader(prompts_train_tokenized, train_df['label'], batch_size=16, pin_memory=True, num_workers=4)\n",
    "test_dataset = DataLoader(prompts_test_tokenized, test_df['label'], batch_size=16, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c536804a732aed9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:07:47.205010Z",
     "start_time": "2024-09-27T22:07:47.199315Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import TrainingArguments to handle the various training configurations\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Define training arguments for fine-tuning\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    logging_dir=\"./results/logs\"\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=64,\n",
    "    tf32=True,\n",
    "    num_train_epochs=3,\n",
    "    torch_compile=True,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True\n",
    "    **default_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f36b1522a52c541a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:08:06.839222Z",
     "start_time": "2024-09-27T22:08:06.830500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to track the model's performance\n",
    "results_df = pd.DataFrame(columns=[\"epoch\",\"accuracy\",\"precision\",\"recall\",\"f1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0bd817fbd7f16e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:08:26.753974Z",
     "start_time": "2024-09-27T22:08:26.749437Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import accuracy metrics\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# A utility function for model evaluation during fine-tuning\n",
    "def evaluate_model(trainer, epoch):\n",
    "    \n",
    "    # Extract predictions and labels\n",
    "    predictions = trainer.predictions.argmax(axis=1)\n",
    "\n",
    "    labels = trainer.label_ids\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    # Calculate precision, recall, and f1 score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
    "    \n",
    "    # Append current metrics to results\n",
    "    global results_df\n",
    "    results_df.loc[len(results_df)] = [epoch, accuracy, precision, recall, f1]\n",
    "        \n",
    "    # Return\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "edccddca7a3676d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:08:45.793722Z",
     "start_time": "2024-09-27T22:08:45.757700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import the Trainer class\n",
    "from transformers import Trainer\n",
    "\n",
    "# Define trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=lambda p: evaluate_model(p, trainer.state.epoch),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2ffd5c792823ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T22:09:18.107894Z",
     "start_time": "2024-09-27T22:09:06.172408Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train(resume_from_checkpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251eeadc807ff2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75379e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"./training_results\"\n",
    "model.save_pretrained(output_dir + \"/ms-deberta-v3-model\")\n",
    "tokenizer.save_pretrained(output_dir + \"/ms-deberta-v3-tokenizer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
