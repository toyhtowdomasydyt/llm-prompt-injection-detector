{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACTS_BASE = '../../../artifacts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "from datasets import load_from_disk\n",
    "\n",
    "dataset_path = path.join(ARTIFACTS_BASE, 'datasets', 'jayavibhav/prompt-injection')\n",
    "\n",
    "test_dataset = load_from_disk(path.join(dataset_path, 'test'))\n",
    "test_dataset = test_dataset.rename_column('text', 'prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a model for identifying toxic content. Output must be 'toxic' or 'non-toxic'\"},\n",
    "    {\"role\": \"user\", \"content\": \"JEW Get the fuck out of here you jewish son of a bitch, I'll rape your fucking family if you don't leave you semite bastard. I will shoot you if you return, because you're a dirty semite, I hope you choke on a fucking bagel, prick. Shalom. We Came In?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"toxic\"},\n",
    "    {\"role\": \"user\", \"content\": \"Men are still ten times more likely to die on the job. As we get more \\\"equality\\\", I don't see women taking dangerous jobs from men. Women are taking safe jobs from men so even more men will die on the job. If we were to have a another Vietnam (60,000 killed), 97% will be men. Men die earlier than women, but spending on woman's healthcare research (breast, ovarian cancer etc.) is four (4) times greater than the sending on mens healthcare research (prostate, testicular cancer etc.). The list goes on.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"non-toxic\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_args = {\n",
    "    \"max_new_tokens\": 15,\n",
    "    \"return_full_text\": False,\n",
    "    \"temperature\": 0.0,\n",
    "    \"do_sample\": False,\n",
    "}\n",
    "\n",
    "new_messages = messages + [{\"role\": \"user\", \"content\": \"Some nice words about you\"}]\n",
    "output = pipe(new_messages, **generation_args)\n",
    "text = output[0][\"generated_text\"]\n",
    "label = \"\"\n",
    "if \"non-toxic\" in text:\n",
    "    label = \"non-toxic\"\n",
    "else:\n",
    "    label = \"toxic\"\n",
    "\n",
    "print(label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
